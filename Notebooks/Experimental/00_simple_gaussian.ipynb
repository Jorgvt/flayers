{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experimental.gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Gaussian\n",
    "\n",
    "> Implement a very simple gaussian without rotations of domain.\n",
    "\n",
    "We're finding some struggle when working with full complex gaussians and gabors, specially in the domain rotation, so we're going to try very simple gaussians that don't use matrix inversions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from einops import rearrange, repeat, reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os; os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base formula\n",
    "\n",
    "Following [Wikipedia](https://en.wikipedia.org/wiki/Gaussian_function#Two-dimensional_Gaussian_function), a two dimensional elliptical Gaussian is expressed as:\n",
    "\n",
    "$$\n",
    "f(x,y) = A e^{-(a(x-x_0)^2 + 2b(x-x_0)(y-y_0) + c(y-y_0)^2)}\n",
    "$$\n",
    "\n",
    "where the matrix \n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "b & c\n",
    "\\end{bmatrix}\n",
    "\n",
    "must be positive-definite, meaning that $ac - b^2 > 0$.\n",
    "\n",
    "**Parameters**:\n",
    "- $A$: height of the peak.\n",
    "- $x_0$ and $y_0$ represent the center of the gaussian.\n",
    "- $a = \\frac{cos^2\\theta}{2\\sigma_x^2}$ + \\frac{cos^2\\theta}{2\\sigma_x^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, as well, use this other formulation:\n",
    "\n",
    "$$\n",
    "f(x,y) = Ae^{-(\\frac{(x-x_0)^2}{2\\sigma_x^2} + \\frac{(y-y_0)^2}{2\\sigma_y^2})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_gaussian(x, y, x0, y0, sigma_x, sigma_y, A=1):\n",
    "    return A*np.exp(-((x-x0)**2/(2*sigma_x**2)+(y-y0)**2/(2*sigma_y**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 11), (11, 11))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0, y0 = 5, 5\n",
    "x, y = np.meshgrid(range(11), range(11))\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = simple_gaussian(x, y, 5, 5, 2, 2)\n",
    "g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(g)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to put this into a layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0.1,10), np.log(np.linspace(0.1,10)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class SimpleGaussian(layers.Layer):\n",
    "    \"\"\"Simple gaussian layer.\"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 filters,\n",
    "                 kernel_size,\n",
    "                 A=1, # Height of the peak of the Gaussian.\n",
    "                 strides=1, # Strides of the convolution.\n",
    "                 padding=\"SAME\", # Can be \"SAME\" or \"VALID\".\n",
    "                 normalize=True, # Wether to normalize the output filters or not.\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        super(SimpleGaussian, self).__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.A = tf.cast(A, dtype=tf.float32)\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def build(self,\n",
    "              input_shape,\n",
    "              ):\n",
    "        self.x0 = tf.Variable([self.kernel_size//2]*self.filters, trainable=True, name=\"x0\", dtype=tf.float32)\n",
    "        self.y0 = tf.Variable([self.kernel_size//2]*self.filters, trainable=True, name=\"y0\", dtype=tf.float32)\n",
    "        self.logsigma_x = tf.Variable(np.random.uniform(low=-2, high=2, size=self.filters), trainable=True, name=\"logsigma_x\", dtype=tf.float32)\n",
    "        self.logsigma_y = tf.Variable(np.random.uniform(low=-2, high=2, size=self.filters), trainable=True, name=\"logsigma_y\", dtype=tf.float32)\n",
    "\n",
    "    @property\n",
    "    def sigma_x(self):\n",
    "        return tf.math.exp(self.logsigma_x)\n",
    "\n",
    "    @property\n",
    "    def sigma_y(self):\n",
    "        return tf.math.exp(self.logsigma_y)\n",
    "\n",
    "    def call(self,\n",
    "             X,\n",
    "             training=False,\n",
    "             ):\n",
    "        \n",
    "        ## 1. Build the filters (n_filters, kernel_size, kernel_size)\n",
    "        filters = self.build_filters()\n",
    "\n",
    "        ## 2. Reshape so they match what Keras expects (Kx, Ky, Cin, Cout)\n",
    "        filters = repeat(filters, \"n_filters kx ky -> kx ky Cin n_filters\", Cin=X.shape[-1])\n",
    "\n",
    "        return tf.nn.conv2d(X, filters, strides=self.strides, padding=self.padding)\n",
    "    \n",
    "    @tf.function\n",
    "    def _build_filter(self,\n",
    "                      x, # X domain.\n",
    "                      y, # Y domain.\n",
    "                      x0, # Mean of X.\n",
    "                      y0, # Mean of Y.\n",
    "                      sigma_x, # Width of X.\n",
    "                      sigma_y, # Width of Y.\n",
    "                      A, # Height of the peak.\n",
    "                      ):\n",
    "        \"\"\"Builds the gaussian filters using the parameters of the layer.\"\"\"\n",
    "\n",
    "        ## 2. Build the gaussian\n",
    "        if self.normalize: A = 1/(2*3.14*sigma_x*sigma_y)\n",
    "        return A*tf.math.exp(-((x-x0)**2/(2*sigma_x**2)+(y-y0)**2/(2*sigma_y**2)))\n",
    "\n",
    "    @tf.function\n",
    "    def build_filters(self):\n",
    "        ## 1. Build domain\n",
    "        x, y = tf.meshgrid(tf.range(self.kernel_size), tf.range(self.kernel_size))\n",
    "        x, y = tf.cast(x, dtype=tf.float32), tf.cast(y, dtype=tf.float32)\n",
    "        \n",
    "        ## 2. Initialize empty `TensorArray`\n",
    "        filters = tf.TensorArray(dtype = tf.float32, size = self.filters)\n",
    "\n",
    "        for n in tf.range(start=0, limit=self.filters, dtype=tf.int32):\n",
    "            filters = filters.write(n, \n",
    "                                    self._build_filter(x, y, \n",
    "                                                       tf.gather(self.x0, n), tf.gather(self.y0, n), \n",
    "                                                       tf.gather(self.sigma_x, n), tf.gather(self.sigma_y, n),\n",
    "                                                       self.A))\n",
    "\n",
    "        filters = filters.stack()\n",
    "        # Normalize the filters\n",
    "        # if self.normalize: \n",
    "        #     max_per_filter = reduce(filters, \"filters Ncols Nrows -> filters () ()\", \"max\")\n",
    "        #     min_per_filter = reduce(filters, \"filters Ncols Nrows -> filters () ()\", \"min\")\n",
    "        #     filters = (filters-min_per_filter)/(max_per_filter-min_per_filter)\n",
    "        return filters\n",
    "\n",
    "    def show_filters(self,\n",
    "                     show=True, # Wether to do plt.show() or not.\n",
    "                     ):\n",
    "        \"\"\"Plots the filters created with the current parameters.\"\"\"\n",
    "        ncols = int(np.sqrt(self.filters))\n",
    "        nrows = int(self.filters-ncols)\n",
    "        if nrows == 0: nrows == 1\n",
    "        filters = self.build_filters().numpy()\n",
    "        fig, axes = plt.subplots(ncols, nrows)\n",
    "        for filter, ax in zip(filters, axes.ravel()):\n",
    "            ax.imshow(filter)\n",
    "            ax.axis(\"off\")\n",
    "        if show: plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-09 20:07:45.328185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5435 MB memory:  -> device: 0, name: NVIDIA GeForce GTX TITAN Black, pci bus id: 0000:84:00.0, compute capability: 3.5\n"
     ]
    }
   ],
   "source": [
    "gl = SimpleGaussian(filters=4, kernel_size=11)\n",
    "gl.build(())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-09 20:07:46.028716: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gl.show_filters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "\n",
    "X_train = X_train/255.0\n",
    "X_test = X_test/255.0\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_gaussian_1 (SimpleGau (None, 32, 32, 4)         16        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 4)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                50        \n",
      "=================================================================\n",
      "Total params: 66\n",
      "Trainable params: 66\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    SimpleGaussian(filters=4, kernel_size=11, input_shape=X_train[0].shape),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-09 20:07:55.155221: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8100\n",
      "2022-10-09 20:07:55.618908: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 19ms/step - loss: 2.4712 - accuracy: 0.0926 - val_loss: 2.3077 - val_accuracy: 0.1027\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 2.3007 - accuracy: 0.0983 - val_loss: 2.2971 - val_accuracy: 0.1057\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 2.2957 - accuracy: 0.1097 - val_loss: 2.2928 - val_accuracy: 0.1087\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 2.2918 - accuracy: 0.1157 - val_loss: 2.2889 - val_accuracy: 0.1155\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 2.2884 - accuracy: 0.1175 - val_loss: 2.2854 - val_accuracy: 0.1249\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=5, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'simple_gaussian_1/x0:0' shape=(4,) dtype=float32, numpy=array([4.924662 , 4.7507434, 5.2441254, 4.725989 ], dtype=float32)>,\n",
       " <tf.Variable 'simple_gaussian_1/y0:0' shape=(4,) dtype=float32, numpy=array([3.9362297, 5.3472905, 4.764661 , 5.4276137], dtype=float32)>,\n",
       " <tf.Variable 'simple_gaussian_1/logsigma_x:0' shape=(4,) dtype=float32, numpy=array([ 1.4867465, -1.5360956,  1.9485881, -1.6307621], dtype=float32)>,\n",
       " <tf.Variable 'simple_gaussian_1/logsigma_y:0' shape=(4,) dtype=float32, numpy=array([-0.6090842,  1.7246387,  1.6410862,  0.899996 ], dtype=float32)>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].trainable_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it into a GDN\n",
    "\n",
    "> Now that we saw that we can optimize the gaussian's parameters, let's put it into a GDN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDNConv(layers.Layer):\n",
    "    \"\"\"GDN that takes as input a specific layer to use.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 layer, # Layer to be used to extract the normalization.\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        super(GDNConv, self).__init__(**kwargs)\n",
    "        self.layer = layer\n",
    "\n",
    "    def build(self,\n",
    "              input_shape,\n",
    "              ):\n",
    "        self.layer.build(input_shape)\n",
    "        self.alpha = tf.Variable(2, trainable=False, name=\"alpha\", dtype=tf.float32)\n",
    "        self.epsilon = tf.Variable(1/2, trainable=False, name=\"epsilon\", dtype=tf.float32)\n",
    "        # self.beta = tf.Variable(1, trainable=True, name=\"beta\", dtype=tf.float32)\n",
    "\n",
    "    def call(self,\n",
    "             X,\n",
    "             training=False,\n",
    "             ):\n",
    "        norm = tf.math.pow(X, self.alpha)\n",
    "        norm = self.layer(norm, training=training)#+self.beta\n",
    "        norm = tf.math.pow(norm, self.epsilon)\n",
    "        # norm = tf.clip_by_value(norm, clip_value_min=1e-5, clip_value_max=tf.reduce_max(norm))\n",
    "        return X / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gdn_conv_4 (GDNConv)         (None, 32, 32, 3)         14        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_5 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,240\n",
      "Trainable params: 1,238\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    GDNConv(SimpleGaussian(filters=3, kernel_size=11), input_shape=X_train[0].shape),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gdn_conv (GDNConv)           (None, 32, 32, 3)         14        \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 1,240\n",
      "Trainable params: 1,226\n",
      "Non-trainable params: 14\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.layers[0].trainable=False\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 19ms/step - loss: 2.3027 - accuracy: 0.1001 - val_loss: 2.3027 - val_accuracy: 0.0952\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=1, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gdn_conv_4/simple_gaussian_6/x0:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_4/simple_gaussian_6/y0:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_4/simple_gaussian_6/logsigma_x:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_4/simple_gaussian_6/logsigma_y:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_4/alpha:0' shape=() dtype=float32, numpy=2.0>,\n",
       " <tf.Variable 'gdn_conv_4/epsilon:0' shape=() dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step by step\n",
    "\n",
    "> Let's see if we can find anything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    GDNConv(SimpleGaussian(filters=3, kernel_size=11), input_shape=X_train[0].shape),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "# model.summary()\n",
    "model.build((28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = tf.data.Dataset.from_tensor_slices((X_train.astype(np.float32), Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "activations = {layer.name:[] for layer in model.layers}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for X, Y in dst_train.batch(BATCH_SIZE):\n",
    "        for i, layer in enumerate(model.layers):\n",
    "            if i==0: \n",
    "                output = layer(X, training=True)\n",
    "            else:\n",
    "                output = layer(output, training=True)\n",
    "            activations[layer.name].append(output)\n",
    "        break\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gdn_conv_5'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdn_name = list(activations.keys())[0]\n",
    "gdn_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the mean and the standard deviation of the activation of the GDN layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[gdn_name][0].numpy().mean(), activations[gdn_name][0].numpy().std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are `nan`, meaning that at least one element is `nan`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the `nan` are comming from the gaussian filters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.is_nan(model.layers[0].layer.build_filters()).numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There doesn't seem to be any `nan` in the filters, so they should be appearing after the activation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.is_nan(activations[gdn_name]).numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are, in fact, present after the activation. Let's try to find the inputs that correspond to this outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_mask = tf.math.is_nan(activations[gdn_name]).numpy().squeeze()\n",
    "X.numpy()[nan_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are all 0s. This could mean that, if every pixel that participates in the convolution is 0, the result is going to be 0, and dividing by 0 could result in `nan`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1270"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X.numpy()==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.32486203, 0.95938575, 0.986067  ],\n",
       "         [0.32354212, 0.99455976, 0.7339644 ],\n",
       "         [0.35746002, 0.8021005 , 0.680817  ],\n",
       "         ...,\n",
       "         [0.39661583, 0.7808594 , 0.5922851 ],\n",
       "         [0.4000493 , 0.76971984, 0.5784924 ],\n",
       "         [0.39535943, 0.7839518 , 0.6644451 ]],\n",
       "\n",
       "        [[0.2884099 , 0.30474618, 0.4155387 ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.5262817 , 0.10727825, 0.        ],\n",
       "         ...,\n",
       "         [0.44587988, 0.48746446, 0.31017557],\n",
       "         [0.45228204, 0.47743067, 0.29315236],\n",
       "         [0.444957  , 0.52461636, 0.38046837]],\n",
       "\n",
       "        [[0.36125875, 0.36714813, 0.5940494 ],\n",
       "         [0.5206313 , 0.12500215, 0.        ],\n",
       "         [0.50469726, 0.28820127, 0.1121923 ],\n",
       "         ...,\n",
       "         [0.44908923, 0.47829077, 0.31212565],\n",
       "         [0.4525718 , 0.49748114, 0.32849023],\n",
       "         [0.46237442, 0.4690638 , 0.32801053]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.42642906, 0.5655689 , 0.40013632],\n",
       "         [0.45988345, 0.5852939 , 0.13493536],\n",
       "         [0.4504334 , 0.62122166, 0.10572007],\n",
       "         ...,\n",
       "         [0.42628962, 0.47218147, 0.3411404 ],\n",
       "         [0.49718294, 0.20844463, 0.05293528],\n",
       "         [0.46902573, 0.3114541 , 0.27200785]],\n",
       "\n",
       "        [[0.4264811 , 0.5062699 , 0.43475115],\n",
       "         [0.46603125, 0.5078721 , 0.17804535],\n",
       "         [0.4577213 , 0.58185273, 0.12520245],\n",
       "         ...,\n",
       "         [0.42350814, 0.54914516, 0.42043057],\n",
       "         [0.4685383 , 0.43251923, 0.2056661 ],\n",
       "         [0.46545172, 0.46471918, 0.31255966]],\n",
       "\n",
       "        [[0.40439633, 0.6186642 , 0.6096576 ],\n",
       "         [0.42272267, 0.6218468 , 0.45910054],\n",
       "         [0.42723912, 0.6569095 , 0.41501206],\n",
       "         ...,\n",
       "         [0.39907613, 0.7559929 , 0.61970544],\n",
       "         [0.42029524, 0.8560032 , 0.4685023 ],\n",
       "         [0.4234567 , 0.8193166 , 0.5748711 ]]],\n",
       "\n",
       "\n",
       "       [[[0.30032083, 0.71380824, 0.8761899 ],\n",
       "         [0.3187444 , 0.6259729 , 0.6501796 ],\n",
       "         [0.34823304, 0.5932579 , 0.53940517],\n",
       "         ...,\n",
       "         [0.35514772, 0.7272897 , 0.5455012 ],\n",
       "         [0.35278118, 0.77879745, 0.5890474 ],\n",
       "         [0.34700966, 0.7382825 , 0.6927358 ]],\n",
       "\n",
       "        [[0.30140457, 0.5751047 , 0.7152022 ],\n",
       "         [0.32424363, 0.60133326, 0.6319318 ],\n",
       "         [0.34274757, 0.60140365, 0.545314  ],\n",
       "         ...,\n",
       "         [0.35382518, 0.67802274, 0.5394252 ],\n",
       "         [0.35298517, 0.6258359 , 0.4789044 ],\n",
       "         [0.34956816, 0.5837187 , 0.5667061 ]],\n",
       "\n",
       "        [[0.3082705 , 0.53755736, 0.71106756],\n",
       "         [0.32369944, 0.53406394, 0.610309  ],\n",
       "         [0.33886114, 0.5002118 , 0.49615315],\n",
       "         ...,\n",
       "         [0.3528619 , 0.5494524 , 0.4735846 ],\n",
       "         [0.35394666, 0.53232217, 0.45927903],\n",
       "         [0.35352102, 0.5111954 , 0.53705096]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3488233 , 0.55348074, 0.678748  ],\n",
       "         [0.3352407 , 0.5484331 , 0.6058421 ],\n",
       "         [0.3213767 , 0.6104138 , 0.6630021 ],\n",
       "         ...,\n",
       "         [0.3770181 , 0.20198634, 0.30375516],\n",
       "         [0.3593088 , 0.29762626, 0.39691684],\n",
       "         [0.35269105, 0.39544407, 0.6159992 ]],\n",
       "\n",
       "        [[0.37179533, 0.5574402 , 0.5536619 ],\n",
       "         [0.35873362, 0.57922095, 0.50594157],\n",
       "         [0.3475418 , 0.6188655 , 0.5545244 ],\n",
       "         ...,\n",
       "         [0.35608524, 0.53804713, 0.5631473 ],\n",
       "         [0.34814084, 0.60995513, 0.62847704],\n",
       "         [0.34619418, 0.5826168 , 0.7206906 ]],\n",
       "\n",
       "        [[0.38005033, 0.6309158 , 0.61492825],\n",
       "         [0.3708875 , 0.65325373, 0.5554126 ],\n",
       "         [0.36334497, 0.6722252 , 0.6033625 ],\n",
       "         ...,\n",
       "         [0.3480944 , 0.80197483, 0.7355761 ],\n",
       "         [0.34477347, 0.74998266, 0.7216648 ],\n",
       "         [0.34454757, 0.6972899 , 0.8039887 ]]],\n",
       "\n",
       "\n",
       "       [[[0.33753836, 0.65167433, 0.7516829 ],\n",
       "         [0.33685726, 0.64667654, 0.665548  ],\n",
       "         [0.3368677 , 0.6466941 , 0.6629877 ],\n",
       "         ...,\n",
       "         [0.3368677 , 0.64669406, 0.663023  ],\n",
       "         [0.3368677 , 0.64669406, 0.6662987 ],\n",
       "         [0.33752796, 0.64901406, 0.7487141 ]],\n",
       "\n",
       "        [[0.33752796, 0.56597036, 0.6589371 ],\n",
       "         [0.33686763, 0.5655596 , 0.5872256 ],\n",
       "         [0.33686763, 0.5655694 , 0.5846531 ],\n",
       "         ...,\n",
       "         [0.33686763, 0.5655734 , 0.5846687 ],\n",
       "         [0.33686763, 0.5655734 , 0.5875574 ],\n",
       "         [0.33752793, 0.5676024 , 0.66023314]],\n",
       "\n",
       "        [[0.33753315, 0.5300932 , 0.6522785 ],\n",
       "         [0.33686244, 0.52717745, 0.57884455],\n",
       "         [0.3368677 , 0.5271747 , 0.5762444 ],\n",
       "         ...,\n",
       "         [0.33686766, 0.5271972 , 0.5762566 ],\n",
       "         [0.33686766, 0.5271973 , 0.57910377],\n",
       "         [0.33752793, 0.5290887 , 0.65073377]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.33151796, 0.5782519 , 0.6451752 ],\n",
       "         [0.32983613, 0.5816403 , 0.58092177],\n",
       "         [0.3284258 , 0.5709877 , 0.5759456 ],\n",
       "         ...,\n",
       "         [0.3119743 , 0.56464046, 0.61108613],\n",
       "         [0.31464618, 0.5493272 , 0.5941314 ],\n",
       "         [0.31527397, 0.53026587, 0.65489364]],\n",
       "\n",
       "        [[0.3314642 , 0.5999401 , 0.65320754],\n",
       "         [0.32929656, 0.5839697 , 0.5695379 ],\n",
       "         [0.33003598, 0.5797971 , 0.5639395 ],\n",
       "         ...,\n",
       "         [0.31782067, 0.5518476 , 0.5626715 ],\n",
       "         [0.31978866, 0.553334  , 0.5679719 ],\n",
       "         [0.32365665, 0.5898118 , 0.6770977 ]],\n",
       "\n",
       "        [[0.33117917, 0.6622312 , 0.7303847 ],\n",
       "         [0.3299499 , 0.6492766 , 0.6326999 ],\n",
       "         [0.32972315, 0.651874  , 0.6368633 ],\n",
       "         ...,\n",
       "         [0.3203149 , 0.7122338 , 0.70380735],\n",
       "         [0.32307056, 0.7058567 , 0.69157046],\n",
       "         [0.32389697, 0.6892407 , 0.7705161 ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.33755025, 0.6524246 , 0.75359756],\n",
       "         [0.33728677, 0.6553336 , 0.6679471 ],\n",
       "         [0.336885  , 0.67989105, 0.67334676],\n",
       "         ...,\n",
       "         [0.33687294, 0.6453883 , 0.6626289 ],\n",
       "         [0.33684132, 0.64458656, 0.66313016],\n",
       "         [0.33754858, 0.65169626, 0.7529778 ]],\n",
       "\n",
       "        [[0.33753994, 0.56818545, 0.6615616 ],\n",
       "         [0.3332789 , 0.59614456, 0.5941754 ],\n",
       "         [0.33701304, 0.63992095, 0.61733645],\n",
       "         ...,\n",
       "         [0.33687282, 0.5665938 , 0.5855766 ],\n",
       "         [0.33685726, 0.5655331 , 0.58636665],\n",
       "         [0.33753306, 0.5659861 , 0.6596216 ]],\n",
       "\n",
       "        [[0.33755186, 0.5361083 , 0.663147  ],\n",
       "         [0.33513805, 0.5854767 , 0.6072064 ],\n",
       "         [0.34339985, 0.6049721 , 0.6183257 ],\n",
       "         ...,\n",
       "         [0.3368677 , 0.52825534, 0.5769561 ],\n",
       "         [0.33686244, 0.52892804, 0.5796447 ],\n",
       "         [0.3375331 , 0.5301058 , 0.65263045]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.33753315, 0.53010595, 0.65263057],\n",
       "         [0.3368625 , 0.52893865, 0.5796502 ],\n",
       "         [0.3368677 , 0.5282793 , 0.5770776 ],\n",
       "         ...,\n",
       "         [0.37001678, 0.54706687, 0.48864824],\n",
       "         [0.35188648, 0.5885444 , 0.56295115],\n",
       "         [0.34157392, 0.5674439 , 0.6571445 ]],\n",
       "\n",
       "        [[0.33753315, 0.5659861 , 0.6596218 ],\n",
       "         [0.33685726, 0.56553507, 0.58638215],\n",
       "         [0.33687797, 0.5666035 , 0.5859171 ],\n",
       "         ...,\n",
       "         [0.353974  , 0.60927415, 0.5541066 ],\n",
       "         [0.34293377, 0.597466  , 0.5720942 ],\n",
       "         [0.33845904, 0.58730567, 0.6567772 ]],\n",
       "\n",
       "        [[0.3375486 , 0.6516963 , 0.7529781 ],\n",
       "         [0.33684134, 0.6445867 , 0.6631498 ],\n",
       "         [0.3368764 , 0.6453991 , 0.66306114],\n",
       "         ...,\n",
       "         [0.34343544, 0.72891766, 0.6793208 ],\n",
       "         [0.33868596, 0.6819959 , 0.67326486],\n",
       "         [0.33888432, 0.665366  , 0.7546886 ]]],\n",
       "\n",
       "\n",
       "       [[[0.29656625, 0.674019  , 0.8222604 ],\n",
       "         [0.29728633, 0.67100924, 0.72907776],\n",
       "         [0.2966517 , 0.6718606 , 0.72873926],\n",
       "         ...,\n",
       "         [0.3232433 , 0.64305484, 0.6847878 ],\n",
       "         [0.32367554, 0.6437027 , 0.6858828 ],\n",
       "         [0.32367516, 0.6443525 , 0.7710664 ]],\n",
       "\n",
       "        [[0.2970092 , 0.575982  , 0.71404094],\n",
       "         [0.2964095 , 0.57361394, 0.6332179 ],\n",
       "         [0.2970909 , 0.5747146 , 0.6327589 ],\n",
       "         ...,\n",
       "         [0.32593116, 0.56086546, 0.6018382 ],\n",
       "         [0.32635936, 0.5591242 , 0.6051999 ],\n",
       "         [0.32744327, 0.56222045, 0.6770451 ]],\n",
       "\n",
       "        [[0.29566061, 0.5425417 , 0.712016  ],\n",
       "         [0.29641545, 0.5406795 , 0.6315978 ],\n",
       "         [0.2963366 , 0.5419932 , 0.6286104 ],\n",
       "         ...,\n",
       "         [0.3290369 , 0.5281102 , 0.59888285],\n",
       "         [0.32953158, 0.5315959 , 0.6019733 ],\n",
       "         [0.3301361 , 0.5348085 , 0.6761701 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.31975085, 0.51448464, 0.6604405 ],\n",
       "         [0.32966742, 0.5075069 , 0.57947034],\n",
       "         [0.3379743 , 0.5323923 , 0.6008264 ],\n",
       "         ...,\n",
       "         [0.35747463, 0.5174927 , 0.57588303],\n",
       "         [0.3570723 , 0.5203816 , 0.5931155 ],\n",
       "         [0.3576286 , 0.5278938 , 0.65382564]],\n",
       "\n",
       "        [[0.3186247 , 0.5636693 , 0.6872532 ],\n",
       "         [0.32557672, 0.5563174 , 0.6040474 ],\n",
       "         [0.33170563, 0.57175726, 0.6046269 ],\n",
       "         ...,\n",
       "         [0.3553792 , 0.56327677, 0.5708328 ],\n",
       "         [0.35687932, 0.5691363 , 0.5981976 ],\n",
       "         [0.36437148, 0.54307497, 0.62973684]],\n",
       "\n",
       "        [[0.315949  , 0.64698905, 0.77427584],\n",
       "         [0.3212291 , 0.6440765 , 0.6886574 ],\n",
       "         [0.3284014 , 0.6431159 , 0.68655   ],\n",
       "         ...,\n",
       "         [0.34829298, 0.63738394, 0.64936054],\n",
       "         [0.35135472, 0.6106012 , 0.6519224 ],\n",
       "         [0.35974878, 0.5949174 , 0.7065788 ]]],\n",
       "\n",
       "\n",
       "       [[[0.33755878, 0.66275084, 0.75978506],\n",
       "         [0.33683565, 0.68968433, 0.6731453 ],\n",
       "         [0.33685178, 0.66930723, 0.6675541 ],\n",
       "         ...,\n",
       "         [0.33686772, 0.647783  , 0.6638293 ],\n",
       "         [0.3368677 , 0.6477778 , 0.66709465],\n",
       "         [0.337528  , 0.6501018 , 0.7496077 ]],\n",
       "\n",
       "        [[0.33763257, 0.5882781 , 0.6764593 ],\n",
       "         [0.33668098, 0.5851765 , 0.56948876],\n",
       "         [0.33688173, 0.5910508 , 0.5849522 ],\n",
       "         ...,\n",
       "         [0.33686766, 0.5644858 , 0.5837373 ],\n",
       "         [0.33686763, 0.56447846, 0.5865026 ],\n",
       "         [0.33752796, 0.5665036 , 0.6590414 ]],\n",
       "\n",
       "        [[0.33765477, 0.5613597 , 0.6744497 ],\n",
       "         [0.33659515, 0.5583984 , 0.5637983 ],\n",
       "         [0.33690578, 0.58455694, 0.596017  ],\n",
       "         ...,\n",
       "         [0.33687285, 0.5284646 , 0.5776965 ],\n",
       "         [0.3368676 , 0.5284495 , 0.5801977 ],\n",
       "         [0.33752796, 0.5303453 , 0.65194404]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3379163 , 0.51352525, 0.6834415 ],\n",
       "         [0.3358703 , 0.3844642 , 0.4517527 ],\n",
       "         [0.3370347 , 0.414598  , 0.51382726],\n",
       "         ...,\n",
       "         [0.3366777 , 0.4756012 , 0.54871553],\n",
       "         [0.33690545, 0.5244429 , 0.5806622 ],\n",
       "         [0.3376682 , 0.48864958, 0.66033804]],\n",
       "\n",
       "        [[0.33765694, 0.59043175, 0.7077396 ],\n",
       "         [0.33676392, 0.62118757, 0.6192786 ],\n",
       "         [0.33685562, 0.6167493 , 0.63274103],\n",
       "         ...,\n",
       "         [0.33690855, 0.6161569 , 0.5979851 ],\n",
       "         [0.33680257, 0.61086655, 0.5936846 ],\n",
       "         [0.33767527, 0.60056335, 0.69671655]],\n",
       "\n",
       "        [[0.33763307, 0.63405734, 0.7529271 ],\n",
       "         [0.33684787, 0.67093676, 0.65624845],\n",
       "         [0.3368372 , 0.64667463, 0.644899  ],\n",
       "         ...,\n",
       "         [0.33685726, 0.73646474, 0.68858546],\n",
       "         [0.33683538, 0.72071624, 0.68493056],\n",
       "         [0.33764133, 0.7038027 , 0.7872758 ]]]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[gdn_name][0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After clipping the result, we are still getting `nan`, so lets inspect the activation of the gaussian layer itself. It wasn't rising any trouble before, but just in case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'gdn_conv_5/alpha:0' shape=() dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for X, Y in dst_train.batch(BATCH_SIZE):\n",
    "        input_gauss = tf.math.pow(X, model.layers[0].alpha)\n",
    "        act_gauss = model.layers[0].layer(input_gauss)\n",
    "        act_gauss_eps = tf.math.pow(act_gauss, model.layers[0].epsilon)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 102)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.is_nan(act_gauss).numpy().sum(), tf.math.is_nan(act_gauss_eps).numpy().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs of the Gaussian layer don't have any `nan`, but looks like there are negative numbers that are turned into `nan` when doing the power to `epsilon`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This raises a new question because... Should there be negative numbers after the layer? The input is squared, so it should be all positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(input_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, as far as I know, a Gaussian is positive definite..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(model.layers[0].layer.build_filters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we check the minimum value of the activation of the gaussian..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-4.487083e-07>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(act_gauss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that there are negative numbers, but they are so small... Maybe this is all related to a numerical problem after all?\n",
    "\n",
    "We can plot a histogram of the activations of the gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(act_gauss.numpy().ravel(), bins=80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can't even see the negative numbers... Let's count the numbers that are below 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(act_gauss.numpy()<0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curiously enough, there are the same amount of negative numbers that of `nan`... Interesting enough. Let's try to add a clip to the output of the gaussian layer to see if it fixes our `nan` problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDNConv(layers.Layer):\n",
    "    \"\"\"GDN that takes as input a specific layer to use.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 layer, # Layer to be used to extract the normalization.\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        super(GDNConv, self).__init__(**kwargs)\n",
    "        self.layer = layer\n",
    "\n",
    "    def build(self,\n",
    "              input_shape,\n",
    "              ):\n",
    "        self.layer.build(input_shape)\n",
    "        self.alpha = tf.Variable(2, trainable=False, name=\"alpha\", dtype=tf.float32)\n",
    "        self.epsilon = tf.Variable(1/2, trainable=False, name=\"epsilon\", dtype=tf.float32)\n",
    "        # self.beta = tf.Variable(1, trainable=True, name=\"beta\", dtype=tf.float32)\n",
    "\n",
    "    def call(self,\n",
    "             X,\n",
    "             training=False,\n",
    "             ):\n",
    "        norm = tf.math.pow(X, self.alpha)\n",
    "        norm = self.layer(norm, training=training)#+self.beta\n",
    "        norm = tf.clip_by_value(norm, clip_value_min=0, clip_value_max=tf.reduce_max(norm))\n",
    "        norm = tf.math.pow(norm, self.epsilon)\n",
    "        return X / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    GDNConv(SimpleGaussian(filters=3, kernel_size=11), input_shape=X_train[0].shape),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 21ms/step - loss: 2.3026 - accuracy: 0.0966 - val_loss: 2.3027 - val_accuracy: 0.0952\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=1, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gdn_conv_8/simple_gaussian_10/x0:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_8/simple_gaussian_10/y0:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_8/simple_gaussian_10/logsigma_x:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_8/simple_gaussian_10/logsigma_y:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_8/alpha:0' shape=() dtype=float32, numpy=2.0>,\n",
       " <tf.Variable 'gdn_conv_8/epsilon:0' shape=() dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still didn't fix it... Let's inspect the activations again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    GDNConv(SimpleGaussian(filters=3, kernel_size=11), input_shape=X_train[0].shape),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for X, Y in dst_train.batch(BATCH_SIZE):\n",
    "        input_gauss = tf.math.pow(X, model.layers[0].alpha)\n",
    "        act_gauss = model.layers[0].layer(input_gauss)\n",
    "        act_gauss_clip = tf.clip_by_value(act_gauss, clip_value_min=0, clip_value_max=tf.reduce_max(act_gauss))\n",
    "        act_gauss_eps = tf.math.pow(act_gauss_clip, model.layers[0].epsilon)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=-6.968912e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6339989>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(act_gauss), tf.reduce_max(act_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6339989>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(act_gauss_clip), tf.reduce_max(act_gauss_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.62296>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(act_gauss_eps), tf.reduce_max(act_gauss_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least we are not getting `nan` after the power to `epsilon` anymore... Now the problem must be elsewhere... We will look into the division now, it's the only part of the layer we have left. We can predict that there are going to be `nan` because of the division by 0, but we can get around that if we clip our values to a sligtly higher number insted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for X, Y in dst_train.batch(BATCH_SIZE):\n",
    "        input_gauss = tf.math.pow(X, model.layers[0].alpha)\n",
    "        act_gauss = model.layers[0].layer(input_gauss)\n",
    "        act_gauss_clip = tf.clip_by_value(act_gauss, clip_value_min=1e-5, clip_value_max=tf.reduce_max(act_gauss))\n",
    "        act_gauss_eps = tf.math.pow(act_gauss_clip, model.layers[0].epsilon)\n",
    "        X_norm = X / act_gauss_eps\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=-6.968912e-08>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6339989>)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(act_gauss), tf.reduce_max(act_gauss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=1e-05>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.6339989>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(act_gauss_clip), tf.reduce_max(act_gauss_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0031622776>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=1.62296>)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(act_gauss_eps), tf.reduce_max(act_gauss_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=2.5626142>)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(X_norm), tf.reduce_max(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GDNConv(layers.Layer):\n",
    "    \"\"\"GDN that takes as input a specific layer to use.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 layer, # Layer to be used to extract the normalization.\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        super(GDNConv, self).__init__(**kwargs)\n",
    "        self.layer = layer\n",
    "\n",
    "    def build(self,\n",
    "              input_shape,\n",
    "              ):\n",
    "        self.layer.build(input_shape)\n",
    "        self.alpha = tf.Variable(2, trainable=False, name=\"alpha\", dtype=tf.float32)\n",
    "        self.epsilon = tf.Variable(1/2, trainable=False, name=\"epsilon\", dtype=tf.float32)\n",
    "        # self.beta = tf.Variable(1, trainable=True, name=\"beta\", dtype=tf.float32)\n",
    "\n",
    "    def call(self,\n",
    "             X,\n",
    "             training=False,\n",
    "             ):\n",
    "        norm = tf.math.pow(X, self.alpha)\n",
    "        norm = self.layer(norm, training=training)#+self.beta\n",
    "        norm = tf.clip_by_value(norm, clip_value_min=1e-5, clip_value_max=tf.reduce_max(norm))\n",
    "        norm = tf.math.pow(norm, self.epsilon)\n",
    "        return X / norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    GDNConv(SimpleGaussian(filters=3, kernel_size=11), input_shape=X_train[0].shape),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 9s 21ms/step - loss: 2.2276 - accuracy: 0.1646 - val_loss: 2.1436 - val_accuracy: 0.1906\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=1, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gdn_conv_10/simple_gaussian_12/x0:0' shape=(3,) dtype=float32, numpy=array([5.021589 , 5.0748296, 5.033156 ], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_10/simple_gaussian_12/y0:0' shape=(3,) dtype=float32, numpy=array([4.541341 , 5.0774646, 5.2000704], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_10/simple_gaussian_12/logsigma_x:0' shape=(3,) dtype=float32, numpy=array([ 1.5395051, -1.5839721,  0.3694521], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_10/simple_gaussian_12/logsigma_y:0' shape=(3,) dtype=float32, numpy=array([ 0.5664232, -1.3419263, -1.7814674], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_10/alpha:0' shape=() dtype=float32, numpy=2.0>,\n",
       " <tf.Variable 'gdn_conv_10/epsilon:0' shape=() dtype=float32, numpy=0.5>]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IT'S TRAINIG NOW**\n",
    "\n",
    "![HURRAY](https://www.memecreator.org/static/images/memes/5145525.jpg \"HURRAY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Gaussian as inheriting from `Conv2D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGaussian2D(layers.Conv2D):\n",
    "    \"\"\"Simple Gaussian implementation inheriting from Keras' Conv2D.\"\"\"\n",
    "\n",
    "    def build(self,\n",
    "              input_shape,\n",
    "              ):\n",
    "        super(SimpleGaussian2D, self).build(input_shape)\n",
    "        self.x0 = tf.Variable([self.kernel_size[0]//2]*self.filters, trainable=True, dtype=tf.float32)\n",
    "        self.y0 = tf.Variable([self.kernel_size[1]//2]*self.filters, trainable=True, dtype=tf.float32)\n",
    "        self.logsigma_x = tf.Variable(np.random.uniform(low=-2, high=2, size=self.filters), trainable=True, dtype=tf.float32)\n",
    "        self.logsigma_y = tf.Variable(np.random.uniform(low=-2, high=2, size=self.filters), trainable=True, dtype=tf.float32)\n",
    "        self.A = tf.Variable(1, trainable=False, name=\"A\", dtype=tf.float32)\n",
    "\n",
    "    @property\n",
    "    def sigma_x(self):\n",
    "        return tf.math.exp(self.logsigma_x)\n",
    "\n",
    "    @property\n",
    "    def sigma_y(self):\n",
    "        return tf.math.exp(self.logsigma_y)\n",
    "\n",
    "    def call(self,\n",
    "             X,\n",
    "             training=False,\n",
    "             ):\n",
    "        \n",
    "        ## 1. Build the filters (n_filters, kernel_size, kernel_size)\n",
    "        filters = self.build_filters()\n",
    "\n",
    "        ## 2. Reshape so they match what Keras expects (Kx, Ky, Cin, Cout)\n",
    "        filters = repeat(filters, \"n_filters kx ky -> kx ky Cin n_filters\", Cin=X.shape[-1])\n",
    "\n",
    "        # return tf.nn.conv2d(X, filters, strides=self.strides, padding=self.padding)\n",
    "        return self.convolution_op(X, filters)\n",
    "    \n",
    "    # @property\n",
    "    # def kernel(self):\n",
    "    #     ## 1. Build the filters (n_filters, kernel_size, kernel_size)\n",
    "    #     filters = self.build_filters()\n",
    "\n",
    "    #     ## 2. Reshape so they match what Keras expects (Kx, Ky, Cin, Cout)\n",
    "    #     filters = repeat(filters, \"n_filters kx ky -> kx ky Cin n_filters\", Cin=X.shape[-1])\n",
    "\n",
    "    #     return filters\n",
    "\n",
    "    @tf.function\n",
    "    def _build_filter(self,\n",
    "                      x, # X domain.\n",
    "                      y, # Y domain.\n",
    "                      x0, # Mean of X.\n",
    "                      y0, # Mean of Y.\n",
    "                      sigma_x, # Width of X.\n",
    "                      sigma_y, # Width of Y.\n",
    "                      A, # Height of the peak.\n",
    "                      ):\n",
    "        \"\"\"Builds the gaussian filters using the parameters of the layer.\"\"\"\n",
    "\n",
    "        ## 2. Build the gaussian\n",
    "        return A*tf.math.exp(-((x-x0)**2/(2*sigma_x**2)+(y-y0)**2/(2*sigma_y**2)))\n",
    "\n",
    "    @tf.function\n",
    "    def build_filters(self):\n",
    "        ## 1. Build domain\n",
    "        x, y = tf.meshgrid(tf.range(self.kernel_size[0]), tf.range(self.kernel_size[1]))\n",
    "        x, y = tf.cast(x, dtype=tf.float32), tf.cast(y, dtype=tf.float32)\n",
    "        \n",
    "        ## 2. Initialize empty `TensorArray`\n",
    "        filters = tf.TensorArray(dtype = tf.float32, size = self.filters)\n",
    "\n",
    "        for n in tf.range(start=0, limit=self.filters, dtype=tf.int32):\n",
    "            filters = filters.write(n, \n",
    "                                    self._build_filter(x, y, \n",
    "                                                       tf.gather(self.x0, n), tf.gather(self.y0, n), \n",
    "                                                       tf.gather(self.sigma_x, n), tf.gather(self.sigma_y, n),\n",
    "                                                       self.A))\n",
    "\n",
    "        filters = filters.stack()\n",
    "        ## Normalize the filters\n",
    "        # if normalize: \n",
    "        #     max_per_filter = reduce(gaussians, \"filters Ncols Nrows -> filters () ()\", \"max\")\n",
    "        #     gaussians = gaussians/(max_per_filter*tf.cast(filters, tf.float32))\n",
    "        return filters\n",
    "\n",
    "    def show_filters(self,\n",
    "                     show=True, # Wether to do plt.show() or not.\n",
    "                     ):\n",
    "        \"\"\"Plots the filters created with the current parameters.\"\"\"\n",
    "        ncols = int(np.sqrt(self.filters))\n",
    "        nrows = int(self.filters-ncols)\n",
    "        if nrows == 0: nrows == 1\n",
    "        filters = self.build_filters().numpy()\n",
    "        fig, axes = plt.subplots(ncols, nrows)\n",
    "        for filter, ax in zip(filters, axes.ravel()):\n",
    "            ax.imshow(filter)\n",
    "            ax.axis(\"off\")\n",
    "        if show: plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg2d = SimpleGaussian2D(filters=4, kernel_size=11)\n",
    "sg2d.build((None, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sg2d.show_filters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    /tmp/ipykernel_29294/341854560.py:34 call  *\n        return self.convolution_op(X, filters)\n\n    AttributeError: 'SimpleGaussian2D' object has no attribute 'convolution_op'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb Cell 32\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mSequential([\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m     SimpleGaussian2D(filters\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m11\u001b[39;49m, input_shape\u001b[39m=\u001b[39;49mX_train[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mConv2D(filters\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mMaxPool2D(\u001b[39m2\u001b[39;49m),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mGlobalAveragePooling2D(),\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     layers\u001b[39m.\u001b[39;49mDense(\u001b[39m10\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m ])\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmegatron.uv.es/media/disk/users/vitojor/flayers/Notebooks/Experimental/00_simple_gaussian.ipynb#X53sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/engine/sequential.py:134\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m   layers \u001b[39m=\u001b[39m [layers]\n\u001b[1;32m    133\u001b[0m \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m layers:\n\u001b[0;32m--> 134\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd(layer)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py:530\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 530\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/engine/sequential.py:202\u001b[0m, in \u001b[0;36mSequential.add\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    197\u001b[0m     x \u001b[39m=\u001b[39m input_layer\u001b[39m.\u001b[39mInput(\n\u001b[1;32m    198\u001b[0m         batch_shape\u001b[39m=\u001b[39mbatch_shape, dtype\u001b[39m=\u001b[39mdtype, name\u001b[39m=\u001b[39mlayer\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_input\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    199\u001b[0m     \u001b[39m# This will build the current layer\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m# and create the node connecting the current layer\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# to the input layer we just created.\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     layer(x)\n\u001b[1;32m    203\u001b[0m     set_inputs \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[39mif\u001b[39;00m set_inputs:\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/engine/base_layer.py:976\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39m# Functional Model construction mode is invoked when `Layer`s are called on\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[39m# symbolic `KerasTensor`s, i.e.:\u001b[39;00m\n\u001b[1;32m    972\u001b[0m \u001b[39m# >> inputs = tf.keras.Input(10)\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[39m# >> outputs = MyLayer()(inputs)  # Functional construction mode.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[39m# >> model = tf.keras.Model(inputs, outputs)\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[39mif\u001b[39;00m _in_functional_construction_mode(\u001b[39mself\u001b[39m, inputs, args, kwargs, input_list):\n\u001b[0;32m--> 976\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_functional_construction_call(inputs, args, kwargs,\n\u001b[1;32m    977\u001b[0m                                             input_list)\n\u001b[1;32m    979\u001b[0m \u001b[39m# Maintains info about the `Layer.call` stack.\u001b[39;00m\n\u001b[1;32m    980\u001b[0m call_context \u001b[39m=\u001b[39m base_layer_utils\u001b[39m.\u001b[39mcall_context()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/engine/base_layer.py:1114\u001b[0m, in \u001b[0;36mLayer._functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     training_arg_passed_by_framework \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1111\u001b[0m \u001b[39mwith\u001b[39;00m call_context\u001b[39m.\u001b[39menter(\n\u001b[1;32m   1112\u001b[0m     layer\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m, inputs\u001b[39m=\u001b[39minputs, build_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, training\u001b[39m=\u001b[39mtraining_value):\n\u001b[1;32m   1113\u001b[0m   \u001b[39m# Check input assumptions set after layer building, e.g. input shape.\u001b[39;00m\n\u001b[0;32m-> 1114\u001b[0m   outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keras_tensor_symbolic_call(\n\u001b[1;32m   1115\u001b[0m       inputs, input_masks, args, kwargs)\n\u001b[1;32m   1117\u001b[0m   \u001b[39mif\u001b[39;00m outputs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mA layer\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39ms `call` method should return a \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1119\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39mTensor or a list of Tensors, not None \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1120\u001b[0m                      \u001b[39m'\u001b[39m\u001b[39m(layer: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/engine/base_layer.py:848\u001b[0m, in \u001b[0;36mLayer._keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m   \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mmap_structure(keras_tensor\u001b[39m.\u001b[39mKerasTensor, output_signature)\n\u001b[1;32m    847\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 848\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_infer_output_signature(inputs, args, kwargs, input_masks)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/keras/engine/base_layer.py:888\u001b[0m, in \u001b[0;36mLayer._infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    886\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_build(inputs)\n\u001b[1;32m    887\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_cast_inputs(inputs)\n\u001b[0;32m--> 888\u001b[0m     outputs \u001b[39m=\u001b[39m call_fn(inputs, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    890\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n\u001b[1;32m    891\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_mask_metadata(inputs, outputs, input_masks,\n\u001b[1;32m    892\u001b[0m                         build_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf26/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py:695\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m    694\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 695\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m    696\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /tmp/ipykernel_29294/341854560.py:34 call  *\n        return self.convolution_op(X, filters)\n\n    AttributeError: 'SimpleGaussian2D' object has no attribute 'convolution_op'\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    SimpleGaussian2D(filters=3, kernel_size=11, input_shape=X_train[0].shape),\n",
    "    layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"),\n",
    "    layers.MaxPool2D(2),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "313/313 [==============================] - 8s 20ms/step - loss: 2.3027 - accuracy: 0.0997 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
      "Epoch 2/5\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.3027 - accuracy: 0.1003 - val_loss: 2.3027 - val_accuracy: 0.0952\n",
      "Epoch 3/5\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.3027 - accuracy: 0.0998 - val_loss: 2.3028 - val_accuracy: 0.0952\n",
      "Epoch 4/5\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.3027 - accuracy: 0.1012 - val_loss: 2.3027 - val_accuracy: 0.0980\n",
      "Epoch 5/5\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 2.3027 - accuracy: 0.0982 - val_loss: 2.3027 - val_accuracy: 0.0952\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, epochs=5, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'gdn_conv_3/simple_gaussian_14/Variable:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_3/simple_gaussian_14/Variable:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_3/simple_gaussian_14/Variable:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>,\n",
       " <tf.Variable 'gdn_conv_3/simple_gaussian_14/Variable:0' shape=(3,) dtype=float32, numpy=array([nan, nan, nan], dtype=float32)>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.layers[0].layer.trainable_variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('tf26')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0e5e7d3ec6da8cae83531001485d926ded04fa3b6e3dfe28c110c78c0ec74159"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
